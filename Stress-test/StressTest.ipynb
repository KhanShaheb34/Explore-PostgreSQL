{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PostgreSQL Stress Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first we need a lot of data to do the stress test. I tried to use mockaroo to generate a lot of data. But they provide only 1000 rows of data to free user.\n",
    "\n",
    "So, I downloaded 1000 rows of data and wrote this script to generate a million of random data from those 1000 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from random import randint\n",
    "\n",
    "def generate_million_rows(input_path, output_path):\n",
    "    mockData = pd.read_csv(input_path)\n",
    "\n",
    "    million_data = {\n",
    "        \"first_name\": [],\n",
    "        \"last_name\": [],\n",
    "        \"email\": [],\n",
    "        \"gender\": [],\n",
    "        \"country\": [],\n",
    "        \"dob\": [],\n",
    "    }\n",
    "\n",
    "\n",
    "    for i in range(1_000_000):\n",
    "        for col in million_data:\n",
    "            million_data[col].append(mockData[col][randint(0, 999)])\n",
    "\n",
    "    million_dataframe = pd.DataFrame(million_data)\n",
    "    million_dataframe.to_csv(output_path, index=False, header=False)\n",
    "    \n",
    "generate_million_rows('MOCK_DATA.csv', 'MILLION_MOCK_DATA.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to use `psycopg2` to connect PostgreSQL with my python application and I will check the time of every instruction to the database using the `time` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll work on my \"stress\" database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Database\n"
     ]
    }
   ],
   "source": [
    "con = psycopg2.connect(database=\"stress\", user=\"postgres\",\n",
    "                       password=\"\", host=\"127.0.0.1\", port=\"5432\")\n",
    "cur = con.cursor()\n",
    "print(\"Connected to Database\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a function to measure the runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measureTimeOf(fn, args=None, verbose=True):\n",
    "    start_time = time.time()\n",
    "    if(args):\n",
    "        out = fn(args)\n",
    "    else:\n",
    "        out = fn()\n",
    "    run_time = time.time() - start_time\n",
    "    if verbose:\n",
    "        print(\"Time: %ss\" % run_time)\n",
    "    return run_time, out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll create a table and measure how much time it takes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.1529533863067627s\n",
      "Table Created\n"
     ]
    }
   ],
   "source": [
    "def createPersonTable():\n",
    "    cur.execute('''CREATE TABLE person (\n",
    "                    id BIGSERIAL PRIMARY KEY NOT NULL,\n",
    "                    first_name VARCHAR(50) NOT NULL,\n",
    "                    last_name VARCHAR(50) NOT NULL,\n",
    "                    email VARCHAR(150) NOT NULL,\n",
    "                    gender VARCHAR(10) NOT NULL,\n",
    "                    country VARCHAR(50) NOT NULL,\n",
    "                    dob DATE NOT NULL\n",
    "                );''')\n",
    "    con.commit()\n",
    "\n",
    "measureTimeOf(createPersonTable)\n",
    "print(\"Table Created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, it took only 0.153s to create a table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InsertData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will insert 1,000,000 rows that we generated before and measure the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 6.7815399169921875s\n",
      "One million rows inserted to the table.\n"
     ]
    }
   ],
   "source": [
    "def insertOneMillionRows(data_path):\n",
    "    with open(data_path) as data:\n",
    "        cur.copy_from(data, 'person', columns=(\n",
    "            \"first_name\", \"last_name\", \"email\", \"gender\", \"country\", \"dob\"), sep=\",\")\n",
    "    con.commit()\n",
    "    \n",
    "insertion_time, _ = measureTimeOf(insertOneMillionRows, \"MILLION_MOCK_DATA.csv\")\n",
    "print(\"One million rows inserted to the table.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that, it took 6.7815 seconds to insert one million rows to the database. I used `copy_from` instead of SQL `INSERT into`. Beacause inserting a single row at a time is much slower.\n",
    "\n",
    "Now I'll insert another 4 million rows and measure time taken to insert every million. Then we will check the total time to insert all 5 million rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But to insert 4 million rows, we have to generate the data first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    generate_million_rows('MOCK_DATA.csv', 'MILLION_MOCK_DATA_'+str(i)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already loaded 1 million rows. Loading another one million...\n",
      "Time: 5.958866357803345s\n",
      "\n",
      "\n",
      "Already loaded 2 million rows. Loading another one million...\n",
      "Time: 5.923978090286255s\n",
      "\n",
      "\n",
      "Already loaded 3 million rows. Loading another one million...\n",
      "Time: 8.954365968704224s\n",
      "\n",
      "\n",
      "Already loaded 4 million rows. Loading another one million...\n",
      "Time: 6.144176721572876s\n",
      "\n",
      "\n",
      "Total time taken to load 5M rows: 33.76292705535889s\n"
     ]
    }
   ],
   "source": [
    "total_time = insertion_time\n",
    "\n",
    "for i in range(4):\n",
    "    print(\"Already loaded \"+str(i + 1)+\" million rows. Loading another one million...\")\n",
    "    insertion_time, _ = measureTimeOf(insertOneMillionRows, 'MILLION_MOCK_DATA_'+str(i)+'.csv')\n",
    "    total_time += insertion_time\n",
    "    print(\"\\n\")\n",
    "\n",
    "print(\"Total time taken to load 5M rows: %ss\" % total_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Five million rows is already inserted to the database. Now, it's time to check how many seconds it takes to query something from the database.\n",
    "\n",
    "Let's start with a simple query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.18014740943908691s\n",
      "[(100, 'Lu', 'Embury', 'wstpierre6o@japanpost.jp', 'Male', 'Thailand', datetime.date(2005, 1, 24)), (101, 'Dorena', 'Murtell', 'jneylone0@patch.com', 'Male', 'Croatia', datetime.date(1956, 7, 11)), (102, 'Gerome', 'Guly', 'wambridge4o@com.com', 'Male', 'Czech Republic', datetime.date(1980, 12, 14)), (103, 'Cherish', 'Broom', 'gtumeltygp@addtoany.com', 'Male', 'Czech Republic', datetime.date(2002, 8, 24))]\n",
      "[(100, 'Lu', 'Embury', 'wstpierre6o@japanpost.jp', 'Male', 'Thailand', datetime.date(2005, 1, 24)), (101, 'Dorena', 'Murtell', 'jneylone0@patch.com', 'Male', 'Croatia', datetime.date(1956, 7, 11)), (102, 'Gerome', 'Guly', 'wambridge4o@com.com', 'Male', 'Czech Republic', datetime.date(1980, 12, 14)), (103, 'Cherish', 'Broom', 'gtumeltygp@addtoany.com', 'Male', 'Czech Republic', datetime.date(2002, 8, 24))]\n",
      "[(100, 'Lu', 'Embury', 'wstpierre6o@japanpost.jp', 'Male', 'Thailand', datetime.date(2005, 1, 24)), (101, 'Dorena', 'Murtell', 'jneylone0@patch.com', 'Male', 'Croatia', datetime.date(1956, 7, 11)), (102, 'Gerome', 'Guly', 'wambridge4o@com.com', 'Male', 'Czech Republic', datetime.date(1980, 12, 14)), (103, 'Cherish', 'Broom', 'gtumeltygp@addtoany.com', 'Male', 'Czech Republic', datetime.date(2002, 8, 24))]\n",
      "[(100, 'Lu', 'Embury', 'wstpierre6o@japanpost.jp', 'Male', 'Thailand', datetime.date(2005, 1, 24)), (101, 'Dorena', 'Murtell', 'jneylone0@patch.com', 'Male', 'Croatia', datetime.date(1956, 7, 11)), (102, 'Gerome', 'Guly', 'wambridge4o@com.com', 'Male', 'Czech Republic', datetime.date(1980, 12, 14)), (103, 'Cherish', 'Broom', 'gtumeltygp@addtoany.com', 'Male', 'Czech Republic', datetime.date(2002, 8, 24))]\n"
     ]
    }
   ],
   "source": [
    "def selectAllFromPersonWhere(query):\n",
    "    select_query = \"SELECT * FROM person WHERE \" + query\n",
    "    cur.execute(select_query)\n",
    "    data = cur.fetchall()\n",
    "    con.commit()\n",
    "    return data\n",
    "\n",
    "runtime, records = measureTimeOf(selectAllFromPersonWhere, \"id BETWEEN 100 AND 103;\")\n",
    "\n",
    "for row in records:\n",
    "    print(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes 0.18s to run a simple query. Now, I'll run 100,000 queries check how much time it takes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100,000 simple queries took 18.64275074005127 seconds\n"
     ]
    }
   ],
   "source": [
    "total_time = 0.0\n",
    "\n",
    "for i in range(100_000):\n",
    "    random_id = randint(0, 4999999)\n",
    "    runtime, records = measureTimeOf(selectAllFromPersonWhere, \"id=%d;\" % random_id, verbose=False)\n",
    "    total_time += runtime\n",
    "\n",
    "print(\"100,000 simple queries took %s seconds\" % total_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to delete some data and check how much time it takes. Let's act like Thanos and delete half of the data to bring perfect balance. ðŸ˜Ž"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 30.080256462097168s\n",
      "Deleted all rows with even ID.\n"
     ]
    }
   ],
   "source": [
    "def deleteFromPersonWhere(query):\n",
    "    select_query = \"DELETE FROM person WHERE \" + query\n",
    "    cur.execute(select_query)\n",
    "    con.commit()\n",
    "\n",
    "measureTimeOf(deleteFromPersonWhere, \"id%2=0;\")\n",
    "print(\"Deleted all rows with even ID.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, it took 30.08 seconds to delete half od the rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to drop the whole table with 2.5M rows and check how much time does it take."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.5276706218719482s\n",
      "Droped the person table\n"
     ]
    }
   ],
   "source": [
    "def dropPersonTable():\n",
    "    drop_query = \"DROP TABLE person\"\n",
    "    cur.execute(drop_query)\n",
    "    con.commit()\n",
    "\n",
    "measureTimeOf(dropPersonTable)\n",
    "print(\"Droped the person table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Times taken:\n",
    "    \n",
    "* Create table: 0.153s\n",
    "* 1,000,000 row insert: 6.782s\n",
    "* 5,000,000 row insert: 33.763s\n",
    "* 100,000 queries: 18.643s\n",
    "* 2,500,000 row delete: 30.08s\n",
    "* Drop table with 2,500,000 rows: 0.528s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Specs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "OS: Manjaro Linux x86_64 \n",
    "CPU: Intel i5-7200U (4) @ 3.100GHz \n",
    "GPU: NVIDIA GeForce 930MX \n",
    "GPU: Intel HD Graphics 620 \n",
    "Memory: 7638MiB\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python38364bitaed623a5e3e2420d879f9aea8cd25ba4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
